[TOC]

# 交叉验证

不论机器学习，还是深度学习，都需要样本数据。为了训练、学习模型，我们需要训练数据，通过训练样本，我们可以得到一个适配了样本的模型。但是，这还不够，我们还要评估模型的好坏，因为训练的过程，我们可以得到很多的模型，我们也可以利用不同的算法来训练模型，这意味着我们必须要有一个评价模型好坏的方式，这个时候我们需要的就是验证集或者测试集。

验证集或者测试集是为了帮助我们筛选模型的。

上面我们说明了为什么需要验证集，但是为什么我们要采用交叉验证？

之所以要采用交叉验证，是因为我们没有那么多的样本数据时，为了更好的训练和评估模型，这个时候我们才会采用交叉验证。如果数据很多，那么我们可以直接将数据分为训练集、验证集、测试集即可，无需进行交叉验证。

## 什么是交叉验证

前面说了这么多，那么什么是交叉验证呢？更准确的说，交叉验证的思想是什么？

交叉验证其实就是通过合理的方式重复利用数据，或者说是从同一个样本池中随机选择训练集和测试集来获取模型的方式。

交叉验证分为三种：简单留出法、K折交叉验证、留一法。

## 简单交叉验证

随机的将数据分为两部分：训练集和验证集。然后利用训练集训练模型，然后在利用验证集验证模型。

- 优点
简单，只需把数据随机分为两组即可。

- 缺点
这种做法不算严格的交叉验证，因为这里没有“交叉”数据。

## K折交叉验证

将样本均匀分为K份，每次将一份作为验证集，K-1份作为训练集，这样会得到K个模型，用这K个模型在验证集上准确率的平均数作为K折交叉验证下模型的性能指标。

## 留一交叉验证

就是K折交叉验证的极端情形。
