[TOC]

# 决策树

## 决策树的生成

决策树的生成算法：

```text
输入：
```

## 决策树的剪枝

剪枝的核心在于如何判断修剪后泛化能力得到了提升？

### 预剪枝

在决策树构建的过程中，在一个结点处是否进行划分，要判断泛化能力是否得到提升。

优点：

- 节省了计算量，降低了过拟合；

缺点：

- 更容易产生欠拟合风险；
- 过早剪枝可能带来不是最优的风险，贪心思想；

### 后剪枝

决策树构建完成后，自底向上，考察非叶结点，用叶结点替换子树，如果泛化能力提升了，那么就用叶结点替换这颗子树。

优点：

- 不易欠拟合；泛化性能优于预剪枝；

缺点：

- 训练开销大；

### 如何判断泛化能力提升

通过验证集来判断剪枝前后，在局部子数据集上的准确率是否提升了。

## 连续值使用决策树

核心的思想就是将连续值离散化。

## 属性存在缺失值时的处理

缺失值从属性的概率统计角度思考。根据不缺失的值的分配比例来考虑缺失值取不同值的概率，把概率融入到决策树的构建过程中。

## 多变量决策树(斜决策树)
