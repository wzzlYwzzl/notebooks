[TOC]

# 正则化

围绕正则化回答一下几个问题：

- 什么是正则化，为什么正则化？
- 正则化方法有哪些？
- L1范数和L2范数为什么能起到正则化效果？

## 1. 什么是正则化

关于机器学习有不少我们习以为常的名词术语：过拟合、欠拟合、泛化能力等等。这些其实都是在说明评价机器学习的两个关键：在训练样本上表现要好，在测试样本上也要表现好。

为什么训练集上和测试集上不能完全一致呢？

至少有两个原因：

1. 训练集的数据有噪声，模型可能会把噪声拟合进去。这里的噪声也可以理解为数据数据中与输出无关的特征信息。
2. 训练集并不能很好覆盖所有的样本分布，或者说训练集的样本分布和真实样本的分布是不完全一致的。

所以，为了能够很好的得到泛化效果，我们需要引入正则化来避免模型的过拟合。

正则化可以视作损失函数的一种惩罚，对模型的参数进行一定的限制。一般认为，参数值较小的模型比较简单，进而适应不同数据的能力就会更强，泛化能力也就更强。

## 2. 正则化常用方法

机器学习中，我们使用的正则化方法一般就是**L1范数**和**L2范数**。

L1范数：$L1 = |w_1| + |w_2| + ...$
L2范数：$L2 = \sqrt{w_1^2 + w_2^2 + ...}$

带L1正则项和L2正则项的损失函数如下：

$l = l_0 + \alpha\sum{|w_i|}$
$l = l_0 + \lambda\sum{w_i^2}$

其中$l_0$是原始损失函数，$\alpha、\lambda$是正则化系数，用于平衡原始损失函数和正则项。

## 3. L1范数和L2范数的深度讲解

这里不再说明，可以阅读参考文档，其中有很清楚的说明。

## 参考

1. [机器学习中的范数规则化之（一）L0、L1与L2范数](https://blog.csdn.net/zouxy09/article/details/24971995/)
