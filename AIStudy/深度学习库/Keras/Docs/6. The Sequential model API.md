[TOC]

# Sequential模型的API

Sequential模型有以下核心的方法：

- compile: 配置模型训练过程的信息。
- fit: 传入训练数据，开始训练。
- evaluate: 对测试数据进行评估。
- predict: 使用模型预测数据。

这四个方法是模型的四个过程，是对利用模型解决问题过程的抽象。下面分别介绍这几个方法的使用方式。

## compile函数

```python
compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)
```

- optimizer: 优化器，str类型或者optimizer实例。

- loss: 目标函数或者说损失函数，str类型或者Loss实例；如果模型有多个outputs，可以为每个输出定义一个损失函数，方式就是传入loss的dict或者是list，这个时候损失就是多个损失函数的和。

- metrics: list, 模型训练和测试过程中使用的评估指标。同常使用是metrics=['accuracy']。如果是多个输出，那么可以传入一个dict，为每个输出指定指标，比如：metrics={'output_a':'accuracy', 'output_b':['accuracy','mse']}，当然，也可以传入如下形式的list：[['accuracy'],['accuracy','mse']] 或者 metrics=['accuracy',['accuracy','mse']]

- loss weights: 如果损失函数有多个，且这些损失函数对于训练模型的比重不一样，那么可以为这些损失函数指定权重。和loss一样，可以是list，也可以是dict，如果是list，那么就要和loss一一对应，如果是dict，那么通过指定output name来为相应损失函数指定权重。

- sample_weight_mode: If you need to do timestep-wise sample weighting (2D weights), set this to "temporal". None defaults to sample-wise weights (1D). If the model has multiple outputs, you can use a different sample_weight_mode on each output by passing a dictionary or a list of modes.

- weighted_metrics: List of metrics to be evaluated and weighted by sample_weight or class_weight during training and testing.

- target_tensors: By default, Keras will create placeholders for the model's target, which will be fed with the target data during training. If instead you would like to use your own target tensors (in turn, Keras will not expect external Numpy data for these targets at training time), you can specify them via the target_tensors argument. It can be a single tensor (for a single-output model), a list of tensors, or a dict mapping output names to target tensors.

## fit函数

```python
fit(x=None, y=None,
    batch_size=None,
    epochs=1,
    verbose=1,
    callbacks=None,
    validation_split=0.0,
    validation_data=None,
    shuffle=True,
    class_weight=None,
    sample_weight=None,
    initial_epoch=0,
    steps_per_epoch=None,
    validation_steps=None,
    validation_freq=1,
    max_queue_size=10,
    workers=1,
    use_multiprocessing=False)
```

- x: 输入数据，可以有如下形式：
  1. Numpy array，如果有多个输入，那么就是list[numpy array]；
  2. dict，key就是输入的name，value是array或tensors；
  3. 一个生成器或者keras.utils.Sequence，输出(inputs, targets)或者(inputs,targets,sample weights)。
  4. None，表示输入的是框架自身的tensors。

- y: Target数据。和x一样，可以有如下形式：
  1. Numpy array；
  2. 框架自身的tensor；
  3. 如果模型有多个输出，可以是list[numpy array];
  4. 如果模型的输出是named，那么y也可以是dict。

- batch_size: int or None，每一次梯度的更新使用的样本数量。如果为None，那么默认是32。如果数据是symbolic tensors或者是generator、Sequence，由于它们本身就会生成batch数据，所以不能指定这个参数。

- epochs: int, 指定要训练模型几轮。一轮就是把输入的x,y数据都训练使用一遍。注意这个参数是和initial_epoch配合使用，它并不是表示训练真正的训练轮数，而是表示训练到这一轮。类似于for(i=initial_epoch;i<=epochs;i++)。

- verbose: int, 可以取值：0，1，2。0表示silent，1表示显示进度条，2表示每个epoch显示一行。

- callback: list of keras.callbacks.Callback实例。在训练和验证过程中使用的回调函数。

- validation_split: 0~1之间的浮点数，指定多少的训练数据用于每个epoch结束后用于验证模型的好坏。如果x是generator或者Sequence，就不支持这个参数。

- validation_data: 用于在每一个epoch结束后评测模型的好坏。如果赋值了这个参数，它会覆盖validation_split。格式是如下形式的tuple：(x_val, y_val)或(x_val,y_val,val_sample_weights)或者是数据集的iterator。如果是前面两种形式，那么需要指定batch_size，如果是最后一种形式，那么需要指定validation_steps。

- shuffle: 在每个epoch结束后，是否随机打乱训练数据。除了是bool类型，也可以是str类型，比如是'batch'，这个值适用于处理HDF5数据，它打乱的是每个batch。

- class_weight: Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to "pay more attention" to samples from an under-represented class.

- sample_weight: Optional Numpy array of weights for the training samples, used for weighting the loss function (during training only). You can either pass a flat (1D) Numpy array with the same length as the input samples (1:1 mapping between weights and samples), or in the case of temporal data, you can pass a 2D array with shape (samples, sequence_length), to apply a different weight to every timestep of every sample. In this case you should make sure to specify sample_weight_mode="temporal" in compile(). This argument is not supported when x generator, or Sequence instance, instead provide the sample_weights as the third element of x.

- initial_epoch: 从哪个epoch开始训练，可以复用之前的训练结果。

- steps_per_epoch: int or None, 每个epoch训练多少步结束。默认的None表示训练(总样本数/batch_size)步。

- validation_steps: 只有在steps_per_epoch设置了才有效，用于验证的step数。

- validation_freq: int,list,tuple,set。只有在validation_data提供了，这个参数才有效。如果是整数，则表示训练多少epoch之后才进行验证，如果是list,set,tuple，则表示依次训练指定epoch之后，才开始验证。

- max_queue_size: int, 只有输入是generator或者Sequence时才有效。表示generator的queue的最大大小。如果不指定，默认是10。

- workers: int, 在输入是generator或Sequence时才有效。多少个进程用于切分数据，如果不指定，默认是1。如果是0，表示在主进程上进行切分。

- use_multiprocessing: bool,当输入是generator或Sequence时才有效。

**返回值**：一个History对象，History.history属性记录了训练时每个epoch的loss值和metrics值，以及验证时的loss值和metrics值。

## evaluate函数

```python
evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)
```

参数说明可以借鉴fit函数的参数说明。

## predict函数

```python
predict(x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)
```

## train_on_batch函数

在单个batch数据上完成单次的梯度更新。

## test_on_batch函数

在单个batch数据上进行测试。

## predict_on_batch函数

在单个batch上进行预测。

## fit_generator函数

```python
fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False)
```

## evaluate_generator函数

## predict_generator函数

## get_layer函数

```python
get_layer(name=None, index=None)
```

根据指定的name或者index来获取layer。如果同时指定name和index，那么index优先使用。
