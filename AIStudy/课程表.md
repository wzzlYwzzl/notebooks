[TOC]

# AI课程表

这里列出掌握AI相关领域知识，称为领域专家需要学习的课程。这些可能是参考一些培训机构的课表给出的，并通过参考不同相关的培训课程逐渐补充相关课程。

为什么创建这样一个课表呢？主要是考虑到有时想要系统学习AI的相关内容时，没有一个很好的方向性知道，所以，希望通过课程表来指引学习的方向，整体把握要学习的相关知识。

需要注意的是，这里的课表不是简单列出一门课程的名称，也会列出一门课程中涉及的基本问题、知识、概念、定理等等。当我们逐个理解了这些知识点，那么对这门课程也就会有基本的认识。

## 1. 数学基础

AI相关的数学基础包括：概率论、线性代数、凸优化等等。

### 1.1 凸优化基础

1. 判断凸集和凸函数
2. 线性规划与二次规划
3. 拉格朗日与对偶函数
4. Strong Duality与KKT条件
5. Non-convex优化问题
6. NP-Hard问题与松弛化处理
7. Discrete Optimization
8. GD,SGD,Adam,Adagrad
9. L-BFGS,ADMM

## 2. 机器学习基础

1. 生成模型与判别模型
2. 最大似然与最大后验估计
3. 模型的过拟合
4. 各类不同的正则(L0,L1,L2)
5. 各类启发式算法(遗传算法、贝叶斯优化等)
6. 随机森林与XGBoost与LightBoost
7. SVM与Dual SVM
8. Kernel Trick与设计核函数

## 3. NLP

### 3.1 文本处理技术与语言模型

1. 最大匹配算法与Jieba技术剖析
2. SkipGram与负采样
3. CBOW，Glove，MF
4. Noisy Channel Model
5. N-Gram模型与各类平滑技术
6. NNLM

### 3.2 序列模型与条件随机场

1. EM算法与GMM
2. 有向图与无向图
3. 条件独立、D-separation
4. HMM模型、Viterbi以及参数估计
5. MEMM与Label Bias问题
6. Log-Linear模型与逻辑回归
7. Linear-CRF与参数估计

### 3.3 RNN与注意力机制

1. 分布式表示的优点
2. RNN与梯度问题
3. LSTM、GRU、Bi-LSTM
4. Seq2Seq与注意力机制
5. Beam Search
6. Bi-LSTM-CRF

### 3.4 预训练模型

#### 3.4.1 ELMo与Transformer

1. 上下文有关的词向量的学习
2. NLU中的层次表示
3. Deep Bi-LSTM与ELMo
4. Bottleneck问题与长依赖问题
5. Self-Attention，Multi-head Attention
6. Transformer与Transformer-XL

#### 3.4.2 Bert与ALBert

1. Autoencoder与DAE
2. MLM语言模型
3. BERT模型
4. BERT-BiLSTM-CRF
5. ALBert模型
6. GPT2模型

#### 3.4.3 XLNet与其他预训练模型

1. AR语言模型
2. Permutation语言模型
3. Two-Stream Attention
4. XLNet模型
5. Roberta
6. Q-Bert，VI-Bert
7. 其他模型(TBD)

### 3.5 知识图谱

#### 3.5.1 信息抽取与知识图谱

1. NE的抽取和识别
2. 基于规则的关系抽取技术
3. 基于无监督、半监督的关系抽取
4. 实体统一、实体消歧、指代消解
5. 知识图谱、实体和关系
6. 知识图谱中的推理

#### 3.5.2 知识嵌入和图神经网络

1. TransE、NTN、Node2Vec模型
2. SDNE模型
3. 带属性的网络嵌入
4. Graph Neural Network
5. CNN与Graph CNN
6. Dynamic Graph的处理
7. Bert与KG的结合

### 3.6 对话系统

1. 智能问答与对话系统
2. 基于检索的对话系统
3. 基于生成式的对话管理
4. 意图识别与有限状态机
5. 基于任务式的对话系统
6. 基于增强学习的对话系统
7. 多轮对话的挑战

### 3.7 文本摘要

1. Abstractive vs Extractive
2. 基于模板的文本摘要生成
3. 基于Seq2Seq的文本摘要生成
4. Rouge与Blue
5. Hierarchical Attention
6. Pointer-Generator Network
7. Beam Search的改造
8. Levenshtein Transformer
9. MASS

## 4. 模型压缩

1. 嵌入设备的模型压缩
2. 基于Sparsity的模型压缩
3. 基于矩阵分解的模型压缩
4. 基于蒸馏方法的模型压缩
5. BERT、Transformer的压缩

## 5. 贝叶斯模型

1. MLE、MAP、Bayesian模型的区别
2. Dropout与Bayesian Approximation
3. PGM与主题模型
4. 吉布斯采样、变分法
5. SGDL与SVI
6. 分布式吉布斯采样

## 6. 可视化与低资源学习

1. 深度学习的可视化技术
2. RNN、LSTM的可视化
3. Layer-wise Relevance Propagation
4. Cross-Domain语言学习
5. Transfer Learning
6. One-shot Learning
