[TOC]

# Python读取大文件的策略

当读取超过1G甚至更大的文件时，如果直接将文件加载到内存，那么势必会加重机器的负担，甚至导致读取失败。

## 1. 最好的方式

```python
with open() as f:
    for line in f:
        pass
```

这种方式会自动使用底层的文件系统地Buffer来管理内存，内存占用小，效率高。

## 2. 分块处理

```python
def read_by_chunks(file, chunk_size):
    with open(file) as f:
        while True:
            chunk_data = f.read(chunk_size)
            if not chunk_data: #如果chunk_data = ''，那么not chunk_data返回的是True
                break
            yield chunk_data
```
