[TOC]

# Python中的同步

Python中，多线程之间的同步机制有以下几种方式：

- 互斥锁
- 递归锁(可重入锁)
- Event
- 信号量

## 1. 互斥锁

每次只有一个线程能够获取这个锁。如果一个线程尝试获取一个没有被释放的锁，那么这个线程就会被阻塞，知道拥有锁的线程释放这个锁。

使用方式：

```python
#创建锁
lock = threading.Lock()

#获取锁
lock.acquire()

#释放锁
lock.release()
```

互斥锁可能会导致死锁的出现。下面简单介绍两种出现死锁的情形：

1. 两个线程交叉获取两把锁，会导致这两个线程的死锁问题。
2. 同一个线程内部，多次获取同一把锁，导致死锁。

## 2. 递归锁

先简单介绍一个递归锁（RLock）的特性：在一个线程内可以被多次的acquire，每一次acquire，那么它内部计数会增加1。释放时，调用release，每一次内部计数会减1，只有计数为0时，其他线程才能获取这个锁。

借助递归锁可以避免死锁。对此，我们进行简单的分析：使用递归锁只能避免上面提到的第二中死锁问题。优势一个线程执行的程序业务比较复杂，出现多层的函数调用，如果外层函数加了锁，那么后面的函数如果也去获取这个锁时，就会导致死锁。对于这种情形可以使用递归锁来避免。

## 3. Event

```python

event = threading.Event()

event.set()

event.wait(timeout)

event.clear()

event.is_set()

```

## 4. 信号量

```python
#初始化方法，数字表示最多几个线程可以获取这个信号量
sem = threading.semaphore(5)

#获取方法
sem.acquire()

#释放方法
sem.release()

```

## 5. GIL

GIL不是Python的特性，而是在实现Python解释器时引入的一个概念。因为在Cpython中有这个特性，但是在其他解释器中没有这个特性。

Global interpreter lock，全局解释器锁，在Cpython中存在的一个锁。

这个锁的作用就是无论硬件有多少个CPU，解释器在同一个时刻只有一个线程在运行，总是使用多线程编程方法，同一时刻也是只会有一个线程在被调度执行。

### 5.1 为什么会有GIL

由于物理上得限制，各CPU厂商在核心频率上的比赛已经被多核所取代。为了更有效的利用多核处理器的性能，就出现了多线程的编程方式，而随之带来的就是线程间数据一致性和状态同步的困难。即使在CPU内部的Cache也不例外，为了有效解决多份缓存之间的数据同步时各厂商花费了不少心思，也不可避免的带来了一定的性能损失。

Python当然也逃不开，为了利用多核，Python开始支持多线程。而解决多线程之间数据完整性和状态同步的最简单方法自然就是加锁。 于是有了GIL这把超级大锁，而当越来越多的代码库开发者接受了这种设定后，他们开始大量依赖这种特性（即默认python内部对象是thread-safe的，无需在实现时考虑额外的内存锁和同步操作）。

慢慢的这种实现方式被发现是蛋疼且低效的。但当大家试图去拆分和去除GIL的时候，发现大量库代码开发者已经重度依赖GIL而非常难以去除了。有多难？做个类比，像MySQL这样的“小项目”为了把Buffer Pool Mutex这把大锁拆分成各个小锁也花了从5.5到5.6再到5.7多个大版为期近5年的时间，本且仍在继续。MySQL这个背后有公司支持且有固定开发团队的产品走的如此艰难，那又更何况Python这样核心开发和代码贡献者高度社区化的团队呢？

所以简单的说GIL的存在更多的是历史原因。如果推到重来，多线程的问题依然还是要面对，但是至少会比目前GIL这种方式会更优雅。

### 5.2 GIL的影响

#### 5.2.1 CPU密集型

如果是CPU密集型的任务，那么因为这个全局锁的影响，带来的问题就是并发的性能不会比串行的性能好，甚至会变得更差。

可以通过如下的代码进行验证。

串行代码如下：

```python
#! /usr/bin/env python

from threading import Thread
import time

def my_counter():
    i = 0
    for _ in range(100000000):
        i = i + 1
    return True

def main():
    thread_array = {}
    start_time = time.time()
    for tid in range(2):
        t = Thread(target=my_counter)
        t.start()
        t.join()
    end_time = time.time()
    print("Total time: {}".format(end_time - start_time))

if __name__ == '__main__':
    main()
```

并行代码如下：

```python
#! /usr/bin/python

from threading import Thread
import time

def my_counter():
    i = 0
    for _ in range(100000000):
        i = i + 1
    return True

def main():
    thread_array = {}
    start_time = time.time()
    for tid in range(2):
        t = Thread(target=my_counter)
        t.start()
        thread_array[tid] = t
    for i in range(2):
        thread_array[i].join()
    end_time = time.time()
    print("Total time: {}".format(end_time - start_time))

if __name__ == '__main__':
    main()
```

#### 5.2.2 IO密集型

如果是IO密集型的任务，那么多线程是能带来大的改善的。

### 5.3 GIL设计的缺陷

基于pcode数量的调度方式

按照Python社区的想法，操作系统本身的线程调度已经非常成熟稳定了，没有必要自己搞一套。所以Python的线程就是C语言的一个pthread，并通过操作系统调度算法进行调度（例如linux是CFS）。为了让各个线程能够平均利用CPU时间，python会计算当前已执行的微代码数量，达到一定阈值后就强制释放GIL。而这时也会触发一次操作系统的线程调度（当然是否真正进行上下文切换由操作系统自主决定）。

伪代码：

```python
while True:
    acquire GIL
    for i in 1000:
        do something
    release GIL
    /* Give Operating System a chance to do thread scheduling */
```

这种模式在只有一个CPU核心的情况下毫无问题。任何一个线程被唤起时都能成功获得到GIL（因为只有释放了GIL才会引发线程调度）。但当CPU有多个核心的时候，问题就来了。从伪代码可以看到，从release GIL到acquire GIL之间几乎是没有间隙的。所以当其他在其他核心上的线程被唤醒时，大部分情况下主线程已经又再一次获取到GIL了。这个时候被唤醒执行的线程只能白白的浪费CPU时间，看着另一个线程拿着GIL欢快的执行着。然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环。

PS：当然这种实现方式是原始而丑陋的，Python的每个版本中也在逐渐改进GIL和线程调度之间的互动关系。例如先尝试持有GIL在做线程上下文切换，在IO等待时释放GIL等尝试。但是无法改变的是GIL的存在使得操作系统线程调度的这个本来就昂贵的操作变得更奢侈了。

### 5.4 如何避免GIL的问题

#### 用multiprocess替代Thread

multiprocess库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。

当然multiprocess也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。就拿计数器来举例子，如果我们要多个线程累加同一个变量，对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocess由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，put再get或者用share memory的方法。这个额外的实现成本使得本来就非常痛苦的多线程程序编码，变得更加痛苦了。具体难点在哪有兴趣的读者可以扩展阅读这篇文章

#### 用其他解析器

之前也提到了既然GIL只是CPython的产物，那么其他解析器是不是更好呢？没错，像JPython和IronPython这样的解析器由于实现语言的特性，他们不需要GIL的帮助。然而由于用了Java/C#用于解析器实现，他们也失去了利用社区众多C语言模块有用特性的机会。所以这些解析器也因此一直都比较小众。毕竟功能和性能大家在初期都会选择前者，Done is better than perfect。

#### 改进Reworking the GIL

- 将切换颗粒度从基于opcode计数改成基于时间片计数
- 避免最近一次释放GIL锁的线程再次被立即调度
- 新增线程优先级功能（高优先级线程可以迫使其他线程释放所持有的GIL锁）

### 5.5 总结

Python GIL其实是功能和性能之间权衡后的产物，它尤其存在的合理性，也有较难改变的客观因素。从本分的分析中，我们可以做以下一些简单的总结：

- 因为GIL的存在，只有IO Bound场景下得多线程会得到较好的性能
- 如果对并行计算性能较高的程序可以考虑把核心部分也成C模块，或者索性用其他语言实现
- GIL在较长一段时间内将会继续存在，但是会不断对其进行改进
